## 编译运行

```sh
docker run -itd --rm -v /root/Develop/TessDS/Data/sz.tess:/root/tessng/Data/UserNets/roadnet.tess -v /tmp/health:/tmp/health --health-cmd="/root/tessng/TessDSHealthCheck" --health-interval=10s --health-timeout=2s --health-retries=3 --env TESS_DS_STATUS=master --env TESS_DS_REDIS_ADDR="tcp://192.168.1.118:6379" --env TESS_DS_MASTER_ONLINE_PORT=7788 --env TESS_DS_MASTER_SVC_NAME="0.0.0.0" --env TESS_DS_MASTER_PORT=31100 --net=host --name tess_ds2_health_test tess_ds2:x86_health_test_20231219
```

```sh
# wsl2-health_check
docker run -itd --rm -v /mnt/d/TessDS/Data/sz.tess:/root/tessng/Data/UserNets/roadnet.tess -v /tmp/health:/tmp/health --health-cmd="/root/tessng/TessDSHealthCheck" --health-interval=10s --health-timeout=3s --health-retries=3 --env TESS_DS_STATUS=master --env TESS_DS_REDIS_ADDR="tcp://192.168.1.118:6379" --env TESS_DS_MASTER_ONLINE_PORT=7788 --env TESS_DS_MASTER_SVC_NAME="0.0.0.0" --env TESS_DS_MASTER_PORT=31100 --net=host --name tess_ds2_health_test tess_ds2:x86_health_test_20231219

# wsl2
docker run -it --rm  -v /mnt/d/TessDS/Data/sz.tess:/root/tessng/Data/UserNets/roadnet.tess --env TESS_DS_STATUS=master --env TESS_DS_REDIS_ADDR="tcp://127.0.0.1:6380" --net=host --name tess_ds2_health_test tess_ds2:x86_health_test_20231219
```

```sh
# windows
docker run -it --rm  -v D:/TessDS/Data/sz.tess:/root/tessng/Data/UserNets/roadnet.tess --health-cmd="/root/tessng/health-check" --health-interval=10s --env TESS_DS_STATUS=master --env TESS_DS_REDIS_ADDR="tcp://192.168.1.118:6379" --net=host --name tess_ds2_health_test tess_ds2:x86_health_test_20231219
```



## 同步逻辑

### libgrape-lite版

| TESS                                                         | DS                                                           |
| :----------------------------------------------------------- | :----------------------------------------------------------- |
| **1：**`PcNet::afterLoadNet()`加载完路网                     |                                                              |
|                                                              | **2：**`DistributedManager::CreateAndQuery(...)`加载路图     |
| **3：**`PcSimulator::beforeStart(...)`开启仿真前             |                                                              |
|                                                              | **4：**`DistributedManager::DoQuery(...)`Grape开始工作       |
|                                                              | **5：**`WorkerJob::IncEval(...)`处理0批次信息                |
| **6：**`PcSimulator::beforeStart(...)`开始仿真               |                                                              |
| **7：**`PcSimulator::afterOneStep(...)`计算完，将本批次驶出信息存放 |                                                              |
|                                                              | **8：**`WorkerJob::IncEval(...)`将驶出信息发送出去           |
| **4：**`PcSimulator::afterOneStep(...)`结束批次              |                                                              |
|                                                              | **5：**`WorkerJob::IncEval(...)`开始接收处理收到的上一批次信息 |
| **6：**`PcSimulator::afterOneStep(...)`开始下一批次          |                                                              |

==循环：7——>8——>4——>5——>6==

- 运行：

  `mpirun -N 1 --allow-run-as-root --hostfile host_info ./TESSNG_Console_linux`

### 自写版：Worker流程（dsAfterOneStep和doOnBatchCompleted并行）

| TESS                                                         | DS                                                           |
| :----------------------------------------------------------- | :----------------------------------------------------------- |
| **1：**`PcNet::afterLoadNet() #end`构建基础路图              |                                                              |
|                                                              | **2：**`DistributedThread::doOnInitialing() #start`接收和确定子路图 |
| **3：**`PcSimulator::beforeStart(...) #start`开启仿真前      |                                                              |
|                                                              | **4：**`DistributedThread::doOnWorking()::doOneBatch() #start`开始工作 |
| **5：**`PcSimulator::beforeStart(...) #end`开始仿真          |                                                              |
| **6：**`PcSimulator::afterOneStep(...) #start`计算完一批次   |                                                              |
|                                                              | **7：**`DistributedThread::doOneBatch() #end`一批次结束。接下来`doOnWorking`发送out和tail车辆 |
|                                                              | **3：**`DistributedThread::doOnSyncing() #end`邻接点信息接收完成。此时一批次信息才算完整 |
|                                                              | **4：**`DistributedThread::doOneBatch() #start`激活下一批次  |
| **5：**`PcSimulator::afterOneStep(...) #end`开始下一批次仿真 |                                                              |

==循环：7——>3——>4——>5——>6==

## 批次信息发送逻辑

### 一些要点

- w1完成批次x，意味着：
  - 对方已收到x-1
  - 己方已收全x-1
- w1收到对方的批次x，意味着：
  - 对方已收全x-1，所以一定收到了己方发去的x-1
  - 己方可能只完成了x-1，x还没开始
- w1要求对方重发，满足条件：
  - 己方已仿真完的批次x >= 对方已知仿真的最新批次
  - 己方已仿真完的批次x 已发送过一次，或者说满足超时条件、重发次数条件等。

### 判断流程

1. 先处理对方要求重发的批次
   - 如果，对方批次 > 己方批次，在处理信息时，直接忽略
   - 否则，重发对方批次号对应的信息，后续流程不再处理
2. 己方主动发送信息
   - 如果，是刚产生的批次x（或者还未满足重发超时条件等），发送，并不要求对方回复
   - 否则，分以下几种场景进行发送
     - 批次数据之前**已发送**，并**发送失败**。发送后，将其设为**need_resp**（该数据在历史数据容器中的）
     - 当前循环里，**没收到该邻接点的数据**，并且**超时（超过一批次仿真时间）**，那么设为**need_resp**，再发送。
       ==意味着：当前批次，己方已经发送了，但没收到对方的数据==

### Tess客户端

#### TessClient启动流程：

- 设置数据源：

  - 通过master获取：

    1. `startConn2Master()`：向master连接

    2. `onConnected()`：连接上后，调用`sendInitReq()`，请求初始化信息

    3. `onRecMessage(...)`：收到master信息，若收到完整的init信息，则调用`init()`，否则调用`sendInitReq()`继续请求

  - 由上层用户提供配置信息：

    1. 设置gClientConfig里的mDataSrcType

    2. 设置相关的参数。如kafka：需要设置`mKafkaAddr`和`mKafkaTopic`
    3. 手动调用`init()`

- `init()`：

  1. 根据数据源类型，绑定数据源，初始化

  2. 绑定信号槽：`newestBatch`和`doOnNewestBatch`

  3. `emit inited()`，由上层用户决定何时开始

- `start()`：

  1. 启动数据源，开始获取数据

  2. 根据同步或异步，分别处理：

     - 若是异步

       - 设置每个run的起始批次

       - `emit started(batch)`

     - 若是同步：

       方法结束后，开始时机由`doOnNewestBatch`决定：当获取到某个完整批次时，便开始：

       - 设置起始批次

       - `emit started(batch)`

#### TessClient获取数据：

TessClient不会按照仿真频率。自动提供批次数据，而是由上层用户手动推进批次。需要使用`TessClient::getNextFullBatchMsgs()`来获取下一批次的所有run获得的数据。

**注意：`getNextFullBatchMsgs()`在同步情况下，获取的是完整的下一个批次数据，每个run产生的数据都是相同批次的；在异步情况下，每个数据的批次都不一定相同**

## TessClientWin运行流程



## 图划分

### Metis

#### 划分步骤

- 根据需要，在TessGraph的基础上，生成GraphLayer

  主要是为了将一些点合在一起，分在一个Tess中。

  - DefaultLayer2：

    - 将面域中的链接段的src路段合成一个TessSuperVertex（继承自TessVertex）。

      - super vertex的id设为`-areaId`

      - super vertex对应的in edge和out edge，是其所包含的原始vertex的edge的合集

    - 没有纳入super vertex的原始vertex不变
    - 更改edge的连接信息，主要将src或dst变更为super vertex的id

- 将GraphLayer key传入`CutGraphWithMetis::initGraphWithLayer(string layer_key)`，将TessVertex，TessEdge，都转为MetisVertex

  - layer中的所有的layer_vertex，layer_edge，都转为图结点MetisVertex对象（**metis_vid**等于layer中的vid或eid）
  - 计算MetisVertex的权重：
    - 若是原始vertex或edge，等于 **对应的路段/连接段的长度 * 其车道数**
    - 若是super vertex，等于 **其所包含的vertex的权重之和**
  - 再用MetisEdge对象连接（edge id从0开始）

- 划分图：`CutGraphWithMetis::cutGraph()`

  - 将MetisVertex，MetisEdge的数据信息，转为metis使用的csr压缩图格式，此时，图结点的id是从0开始的，需要做好映射（与metis_vid的对应关系）。再准备好其它参数，调用其api
  - 返回结果parts数组，等价于kv对：`{vidx: part_id}`

- 根据划分结果parts，返回至Tess

  - 通过vidx确定metis_vid，接着判断其在layer中是什么：
    - 是layer_vertex：
      - 是原始vertex，直接将其分配给对应的node（node_id = part_id + 1）
      - 是super vertex，递归处理其包含的vertex（其也可能是个super vertex）
    - 是layer_edge：
      - 不分配，忽略；存进临时的layer_edge容器中 **[1]**
  - 最后遍历layer_edge容器[1]，根据其对应的原始edge的src/dst id去算连接关系：nbr信息；node的出边，入边信息等

#### 数据结构变化顺序
```cpp
TessGraph{ TessVertex, TessEdge }	
TessGraphLayer{ TessVertex*(TessVertex, TessSuperVertex), TessEdge* }
CutGraphWithMetis{ MetisVertex, MetisEdge }
Metis数据结构
```

#### 划分Api使用说明

##### 路网划分，可以使用Graph下的接口：

![1684464208452](./assets/1684464208452.png)

```cpp
auto pTessGraph = TessGraph::BuildTessGraph();
auto cutWithMetis = new CutGraphWithMetis();
pTessGraph->setCutGraphMethod(cutWithMetis);
// pTessGraph->buildDefaultLayer();
pTessGraph->buildDefaultLayer2();
// cutWithMetis->initGraphWithLayer("default");
cutWithMetis->initGraphWithLayer("default2");
ok = pTessGraph->cutGraph();
```

- `buildDefaultLayer()`

  一个基本路段为图节点，构造的图层

- `buildDefaultLayer2()`

  一个面域中的连接段的`src`路段为一个super点，构造的图层

#### 划分结果

保存在`pTessGraph->mhNodesMap`中，每个node都记录了点和邻接点信息：

```cpp
class TessNode {
public:
	// 结点所对应的子图中的结点
	std::unordered_set<long> mVertexSet;
    // 邻接点id
	std::unordered_set<int> mNbrIdSet;

	// 下游Tess结点id: 下游Tess结点中的边界点ids
	std::unordered_map<long, std::unordered_set<long>> mhToNodeId2LinkId;
	// 上游Tess结点id: 本结点中作为下游的边界点ids
	std::unordered_map<long, std::unordered_set<long>> mhFromNodeId2LinkId;

	int mNodeId;
};
```

## 路由发现

### 方案一：通过HostName环境变量

> 适用于Docker，k8s部署环境

Dell本机HostName：Huth-Dell.mshome.net



## 检测器，采集器等计算

### 车辆需要提供的数据

```cpp
pResult->pos();
vehiID;
pResult->mpVehicle->mVehicleType.vehicleTypeCode;
pResult->mpVehicle->mVehicleType.vehicleTypeName;
pResult->mpVehicle->desirSpeed;
pResult->mpVehicle->Length;
pResult->mpVehicleDriving->mrStartSimuDateTime;
pResult->mpVehicleDriving->mrSimuDateTime;
pResult->speed();
pResult->mpVehicleDriving->mrAcce;
pResult->mpVehicle->Length;
pResult->mpVehicleDriving->mNeighborVehicle.vehiDistFront;
VehicleDriving::RoadAndSegmIndex::mpRoad;
```

### 方案：并发计算再回溯

#### 数据结构

```cpp
// key = batch_num: qc_id: distance
hash<long, hash<long, hash<double, QCDynaData*>>> mhQCDynaData;
// qc的路径基本结构信息
hash<long, QCRoutingSubTree*> mhQCRoutingSubTree;

struct QCDynaData {
    long mBatchNum;
    double mDistance;
    QCRoutingSubTree* mpQCRoutingSubTree;
    hash<string, QCDynaRouting*> mhQCDynaRouting;
}

struct QCDynaRouting {
    string mRoutingId;
    list<long> mlLaneIds;
    // 若无，则nullptr
    QCDynaBackData* mpQCDynaBackData;
}

hash<long, QCDynaBackData*> mhQCDynaBackData;

struct QCDynaBackData {
    // 队伍下游的qc_id
    long mBackQCId;
    QCDynaStatistic mQCDynaStatistic;
}

struct QCDynaStatistic {
    double mQueueLen;
    int mVehiCnt;
}

// QC Routing SubTree结构
struct QCRoutingSubTree {
    // QC的基本信息
    QCInfo mQCInfo;
    long mQCLaneId;
    // 邻接表：车道的上游车道id（即队伍的下游）
    hash<long, hash<long, QCLaneInfo*>> mhAdjacencyTable;
    
}

struct QCLaneInfo {
    long mLaneId;
    // 关联的其它worker上的qc_id
    set<long> mBackQCIds;
}

struct QCInfo {
    GVehicleQueueCounter* mpQC;
}

struct QCLaneData {
    long mLaneId;
    
}

hash<long, QCLaneInfo> mhQCLaneData;


```

#### master准备

- 处理跨结点的排队计数器

  - 用dfs算出所有路径：

    - 遍历过程中，遇到跨结点的初始lane，增加虚拟qc id，关联lane id，node id
    - 路径key的编号为：`[qc_id]-[lane_id]-...-[lane_id]`
    - 递归方法：
      - 当前的lane结点若是某个sub tree的根节点，将sub tree结构保存，关联qc id
      - 若lane结点是sub tree的叶子结点（即其队伍下游是跨界点的），在qc_id下记录lane id和对应的跨界点的qc_id，返回自身lane id。
      - 普通结点：将其分支结构返回，并在分支路径添加上自身的lane_id

    ```cpp
    void dfs(long qc_id, ILane* pLane, string &routingId) {
        // 遍历所有队伍下游lane
        for(auto pBackLane: pLane->fromLanes()) {
            string add_str = "-" + to_string(pBackLane->id());
            auto add_cnt = add_str.size();
            routingId += std::move(add_str);
            // 若pBackLane跨结点，则pParentLane在这条路径上是叶子结点
            if(pBackLane->isOuter()) {
                // 创建新的虚拟qc
                long new_qc_id = createVirtualQC();
                
                dfs(new_qc_id, pBackLane, to_string(new_qc_id));
                
                // 添加新路径
                auto pQCRouting = mhQCRoutingSubTree.at(qc_id)->addRouting(routingId);
                // 关联跨结点的qc_id
                pQCRouting->setBackQCId(new_qc_id);
            }
            // pParentLane在这条路径上是普通结点
            else {
                dfs(qc_id, pBackLane, routingId);
            }
            routingId.resize(routingId.size() - add_cnt);
        }
    }
    ```

    

  - resp_new：

    - 将排队计数器和路径信息，key和mhWorkerConcernQCLaneIds发给每个结点。

  

#### worker工作

##### doOnNotStarted:

- 记录`mhQCData<long, QCData>`：排队计数器对应的所有信息。

  ```cpp
  // qc_id: qc_info
  hash<long, QCInfo> mhQCInfo;
  
  struct QCInfo {
  	long mQCId;
      long mLaneId;
      long mNodeId;
  };
  
  // batch_num: lane_id: QCLaneData*
  map<long, hash<long, QCLaneData*>> mhQCLaneData;
  
  struct QCLaneData {
      long mLaneId;
      double mQueueLen;
      int mVehiCnt;
  };
  
  // batch_num: qc_id: 剩余distance: qc_data
  map<long, hash<long, hash<double, QCData*>>> mhQCData;
  // batch_num: virtual_qc_id: 剩余distance: BackData*
  map<long, hash<long, hash<double, QCBackData*>>> mhQCBackData;
  // batch_num: inner_virtual_qc_id: distance: FrontData*
  map<long, hash<long, hash<double, QCFrontData*>>> mhQCFrontData;
  
  struct QCData {
      // 是否是虚拟的qc
      bool mbIsVirtual;
      // qc
      GVehicleQueueCounter* mpQC;
      // routing_key: routing_info
      hash<string, QCRoutingData*> mhRoutingData;
      set<string> mDoneRoutingIds;
  };
  
  struct QCRoutingData {
      long mRoutingKey;
      // 统计的数据
      double mQueueLen;
      int mVehiCnt;
      // 是否统计完毕
      bool mbDone;
      // 上游qc_id
      optional<long> mFrontQCId;
      // 本worker与队伍下游相连的lane的相关数据
      // back_virtual_qc_id, distance
      optional<pair<long, double>> mhBackDataIds;
      // 关联的QCData
      QCData* mpQCData;
  };
  
  // 本worker与队伍上游相连的lane的相关数据
  struct QCFrontData {
  	long mFrontQCId;
      // 上游发来的数据：
      // 新收到的排队标记
      optional<bool> mbRecvdNeedQueueFlag;
  };
  
  // 本worker与队伍下游相连的QC的相关数据
  struct QCBackData {
      // virtual_qc_id
      long mQCId;
      // 检测的最长排队长度
      double mDistance;
      // 统计的数据
      double mQueueLen;
      int mVehiCnt;
  };
  ```


##### doOnWorking:

- 检查收到的上游的标记`mhQCFrontData::mbRecvdNeedQueueFlag`

  - 若收到不排队，对于本批次中，不排队的qc，则不计算。同时通知下游

  - 计算本结点的qc
    - 计算时间id，看需不需要计算，若不需要则跳过

  - 

## 容灾

### 快照和增量数据的保存

#### **Redis方式**

##### 数据结构

|                    一级key                     | hash二级key  |     hash三级key      |     hash四级key      |  hash五级key   |                value                |
| :--------------------------------------------: | :----------: | :------------------: | :------------------: | :------------: | :---------------------------------: |
| [proj_id]:[plan_id]:snapshot:batch:[batch_num] | simu_config  |                      |                      |                |            仿真配置t快照            |
|                                                |   section    |       [sec_id]       |         base         |                |            道路基础快照             |
|                                                |              |                      | tails:lane:[lane_id] |                |            尾车ghost快照            |
|                                                |  travel_det  |     [travel_id]      |                      |                |         行程时间检测器快照          |
|                                                | signal_group |      [group_id]      |    signal_by_det     |                |           基础信号灯快照            |
|                                                |              |                      | signal_by_dyna_info  |                |        动态创建的信号灯快照         |
|                                                |  msg_graph   | [self_graph_node_id] |        to_nbr        | [nbr_graph_id] |   当前worker向nbr发送的信息的快照   |
|       [proj_id]:[plan_id]:last_batch_num       | simu_config  |                      |                      |                |         仿真配置的最新批次          |
|                                                |   section    |       [sec_id]       |                      |                |           道路的最新批次            |
|                                                | signal_group |      [group_id]      |    signal_by_det     |                |        基础信号灯的最新批次         |
|                                                |              |                      | signal_by_dyna_info  |                |     动态创建的信号灯的最新批次      |
|                                                |  msg_graph   | [self_graph_node_id] |        to_nbr        | [nbr_graph_id] | 当前worker向nbr发送的信息的最新批次 |
|                                                |     job      |       [job_id]       |                      |                |           job最新的批次号           |
|                                                |     job      |       [job_id]       |       snapshot       |                |         job最新的快照批次号         |
| [proj_id]:[plan_id]:inc_data:batch:[batch_num] |   section    |       [sec_id]       |    incoming_vehis    |                |           驶入车辆的数据            |
|                                                |              |                      |     virtual:lane     |   [lane_id]    |           虚拟车辆的数据            |
|      [proj_id]:[plan_id]:snapshot:master       |              |                      |          ds          |     config     |            ds config快照            |
|                                                |              |                      |                      |      base      |           master基础快照            |
|                                                |              |                      |                      |     graph      |              graph快照              |
|                                                |              |                      |                      |      job       |           job manager快照           |
|                                                |              |                      |                      |     worker     |       worker node manager快照       |
|                                                |              |                      |                      |   worker_job   |       worker job manager快照        |
|                                                |              |                      |         tess         |     config     |             config快照              |
|                                                |              |                      |                      |   travel_det   |         行程时间检测器快照          |
|                                                |              |                      |                      | queue_counter  |           排队计数器快照            |
|                                                |              |                      |         all          |                |             所有的快照              |

## 问题排查，注意点

### V2.0容灾测试

#### 注意仿真前，master的快照要删掉

- redis中：key: `snapshot:master`

#### 暂时：inspur那几台机器，每次重启后，设置下coredump
